分布式系统存在的问题
数据同步。是必然的
数据同步过程中的存在的3个问题
（1）网络抖动
（2）节点异常
（3）消息顺序性问题

CAP定理 & BASE理论
CAP定理从这个分布式系统提供的服务出发。进行描述，
Cap定理证明。要保障C则必须放弃A，保障A必须放弃C。P是一定会发生的。
这里的P就是指上诉的3个问题引起的网络分区。

但是从用户角度出发CA都想要，则平衡点BASE理论。

分布式一致性协议
弱一致性协议
gossip
DNS

强一致性协议
paxos
         提案
        阶段
        角色
        接受者2个状态

paxos提出了3个核心的理论，对后续算法有很大的影响
（1）二阶段执行
（2）半数同意
（3）提案顺序递增
fast paxos
multipasox
zab
raft
kraft
jraft

分布式一致性解决模型可以参考mysql数据同步
（1）内部动态，流程图
（2）基于日志的一致性

二阶段提交 & 三阶段提交
参考：分布式事务（ 图解 + 秒懂 + 超级全 ） - 知乎 (zhihu.com)

二阶段提交协议
（1）资源长期锁定，阻塞其他并发事务
（2）第二阶段异常，则可能会导致数据不一致的问题
（3）单点故障问题

1：分布式事务
参考： Part 0: X/Open DTP分布式事务处理模型 - 简书
参考：https://cloud.tencent.com/developer/article/2216104 深入浅出Seata的AT模式
参考：https://baijiahao.baidu.com/s?id=1771136135006362781&wfr=spider&for=pc 分布式事务解决方案Seata AT模式
参考：https://blog.csdn.net/qq_71557143/article/details/141924342 分布式事务解决方案seata架构的安装部署（AT模式）
参考：https://cloud.tencent.com/developer/article/2082639 分布式事务解决方案之TCC（Hmily）「建议收藏」

1.1 分布式事务一致性 VS 分布式副本一致性
1.2 事务强一致性 VS 事务弱一致性
1.3 强一致性XA模式。 
1.4 弱一致性AT模式
1.5 弱一致性TCC
TCC
1.6 基于本地消息表的消息补偿机制的分布式事务一致性
 一种轻量级解决方案，最小成本实现最终一致性。
seata适用于多服务间的事务流程复杂，希望通过框架统一管理，对事务状态管理有较高要求。

1.1 二阶段提交 XA协议

1.2 三阶段提交

1.3 TCC补偿机制

1.4 本地消息表

1.5 MQ事务消息表

2：分布式锁
死锁问题  --> 要考虑分布式锁的过期问题。 这里的死锁是一种广义的死锁。
锁因过期时间提前释放问题 --> 锁定期续期限。必须进行判断是当前线程持有。
锁释放问题 --> 误操作，导致锁有其他进程方式。必须进行判断是否当前进程持有。

锁公平性问题。
锁可重入性问题。

基于redis实现的分布式锁
基于zk实现的分布式锁

3：分布式选举算法


4：分布式一致性算法
paxos算法
解决了 效率低下2个阶段4次通讯
只一致不管一致的内容
活锁
muLti paxos算法
一次承诺 多次accept
选举一个leader

zab算法

raft算法

zab算法选举同raft算法选举的区别
投票机制不同
zab采用优先级投票机制。
这里的优先级是指，选择事务ID更大的候选者，选择服务器ID更大的候选者。
每次投票更新后，会进行广播投票。
初始化投票都是，先投给自己。携带的ZXID中的epoch是不变的仅仅增加counter值，生成一个新的事物ID。

raft采用先到先得的投票机制。同一任期内只能投票给一个 Candidate，先到先得。
初始化投票的时候，也是先投给自己。并且携带的term+1。
投票阶段，采用先到先得的投票机制。
RAFT通过随机选举超时时间来减少选举冲突。

RAFT选举效率是快于zab的。
都是必须获得半数以上的节点的投票才可当选。

zab算法中的同raft算法中的数据复制
是的，ZAB 和 Raft 都采用了类二阶段提交（Two-Phase Commit）的思想和过半确认（Quorum）机制来保证数据一致性，但具体实现细节和侧重点有差异。以下是详细对比：
raft中的数据同步
zab中，Leader 通过PROPOSAL和COMMIT消息同步数据。同时，Leader 定期发送PING消息维持心跳。
在Raft 中，数据同步（日志复制）和心跳机制高度绑定，均通过 AppendEntries RPC 实现。


zab算法中的同raft算法中的日志对齐
zab在选举后，立即强制日志对齐；只有所有节点的日志一致后，才开始向外提供服务。采用的是直接覆盖 --- 具有为 “强实时一致性” 牺牲启动效率
raft算法在leader当选后，直接开始处理新请求，在发送心跳（AppendEntries RPC）时顺便将新日志复制到 Follower，允许 Follower 暂时落后，但通过持续重试机制追上。；采用的是逐步回退。 --- 具有为 “效率和简洁性” 容忍暂时不一致


5： 负载均衡算法
一致性hash算法

6： 限流算法

7： 熔断算法


8： 一致性hash算法

